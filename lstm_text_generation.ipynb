{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_text_generation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "LgTMNQr677kz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM text generation"
      ]
    },
    {
      "metadata": {
        "id": "MhttYUNo77k1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Example script to generate text from text files.\n",
        "\n",
        "At least 20 epochs are required before the generated text starts sounding coherent.\n",
        "\n",
        "It is recommended to run this script on GPU, as recurrent networks are quite computationally intensive.\n",
        "\n",
        "If you try this script on new data, make sure your corpus has at least ~100k characters. ~1M is better."
      ]
    },
    {
      "metadata": {
        "id": "ifH621qw77k2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Input\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import concatenate\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import Sequence\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4RE5YewP77k9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, text, char_indices, batch_size=128, maxlen=40, step=3):\n",
        "        self.text = text\n",
        "        self.char_indices = char_indices\n",
        "        self.batch_size = batch_size\n",
        "        self.maxlen = maxlen\n",
        "        self.step = step\n",
        "\n",
        "    def __len__(self):\n",
        "        return ((len(self.text) - self.maxlen) // self.step) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = np.zeros((self.batch_size, self.maxlen, len(self.char_indices)), dtype=np.bool)\n",
        "        y = np.zeros((self.batch_size, len(self.char_indices)), dtype=np.bool)\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            idx = (i + index) * self.step\n",
        "\n",
        "            for t, char in enumerate(self.text[idx: idx + self.maxlen]):\n",
        "                x[i, t, self.char_indices[char]] = 1\n",
        "\n",
        "            y[i, self.char_indices[self.text[idx + self.maxlen]]] = 1\n",
        "\n",
        "        return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LPPBV02j77lD",
        "colab_type": "code",
        "outputId": "d703240b-1ef1-42ea-becf-0ae184cb9f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "path = get_file(\n",
        "    'lovecraft.txt',\n",
        "    origin='https://bashkirtsevich.pro/shared/lovecraft.txt'\n",
        ")\n",
        "\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://bashkirtsevich.pro/shared/lovecraft.txt\n",
            "23977984/23972914 [==============================] - 6s 0us/step\n",
            "corpus length: 13137488\n",
            "total chars: 123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DjnHLEAQ77lI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "maxlen = 40  # cut the text in semi-redundant sequences of maxlen characters\n",
        "training_generator = DataGenerator(text, char_indices, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HBY-wKj-77lO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build the model: a single LSTM"
      ]
    },
    {
      "metadata": {
        "id": "9o2W_0qw77lR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print(f'----- Generating text after Epoch: {epoch + 1}')\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print(f'----- diversity: {diversity}')\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print(f'----- Generating with seed: \"{sentence}\"')\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "        print(generated)\n",
        "        \n",
        "    model.save(f\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MotBNxq877lU",
        "colab_type": "code",
        "outputId": "759d6659-d023-48ac-dbfb-a13866babdba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "# build/load the model: a single LSTM\n",
        "model_path = None\n",
        "\n",
        "if model_path:\n",
        "    print('Load model...')\n",
        "    model = load_model(model_path)\n",
        "else:\n",
        "    print('Build model...')\n",
        "\n",
        "    num_chars = len(chars)\n",
        "\n",
        "    vec = Input(shape=(maxlen, num_chars))\n",
        "    l1 = LSTM(output_dim=128, activation='tanh', return_sequences=True)(vec)\n",
        "    l1_d = Dropout(0.2)(l1)\n",
        "\n",
        "    input2 = concatenate([vec, l1_d])\n",
        "    l2 = LSTM(output_dim=128, activation='tanh', return_sequences=True)(input2)\n",
        "    l2_d = Dropout(0.2)(l2)\n",
        "\n",
        "    input3 = concatenate([vec, l2_d])\n",
        "    l3 = LSTM(output_dim=128, activation='tanh', return_sequences=True)(input3)\n",
        "    l3_d = Dropout(0.2)(l3)\n",
        "\n",
        "    input_d = concatenate([l1_d, l2_d, l3_d])\n",
        "    \n",
        "    l4 = LSTM(output_dim=128, activation='tanh', return_sequences=False)(input_d)\n",
        "    l4_d = Dropout(0.2)(l4)\n",
        "    \n",
        "    dense3 = Dense(output_dim=num_chars)(l4_d)\n",
        "    output_res = Activation('softmax')(dense3)\n",
        "    \n",
        "    model = Model(input=vec, output=output_res)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(clipnorm=1.), metrics=['accuracy'])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", return_sequences=True, units=128)`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", return_sequences=True, units=128)`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", return_sequences=True, units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", return_sequences=False, units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=123)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8egrG6STg2NA",
        "colab_type": "code",
        "outputId": "e4dcba5d-47cc-4c31-d596-8633f838aab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_20 (InputLayer)           (None, 40, 123)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_37 (LSTM)                  (None, 40, 128)      129024      input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 40, 128)      0           lstm_37[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 40, 251)      0           input_20[0][0]                   \n",
            "                                                                 dropout_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_38 (LSTM)                  (None, 40, 128)      194560      concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 40, 128)      0           lstm_38[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 40, 251)      0           input_20[0][0]                   \n",
            "                                                                 dropout_36[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_39 (LSTM)                  (None, 40, 128)      194560      concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 40, 128)      0           lstm_39[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 40, 384)      0           dropout_35[0][0]                 \n",
            "                                                                 dropout_36[0][0]                 \n",
            "                                                                 dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_40 (LSTM)                  (None, 128)          262656      concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 128)          0           lstm_40[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 123)          15867       dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 123)          0           dense_9[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 796,667\n",
            "Trainable params: 796,667\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BPZY4N2D77la",
        "colab_type": "code",
        "outputId": "b46f716d-7bf4-4e56-f673-ea6e72c2811b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    generator=training_generator,\n",
        "    validation_data=training_generator,\n",
        "    epochs=60,\n",
        "    callbacks=[\n",
        "        LambdaCallback(on_epoch_end=on_epoch_end),\n",
        "        EarlyStopping(monitor=\"loss\", min_delta=0.001, patience=3, mode=\"min\")\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "34212/34212 [==============================] - 17118s 500ms/step - loss: 1.2623 - acc: 0.6101 - val_loss: 0.1660 - val_acc: 0.9635\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"к, проживающий в доме 620 по ист-нэпп-ст\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "к, проживающий в доме 620 по ист-нэпп-стольвой свидались и обратным легон. о помчал полемно объяснял попастетение молеча принилоси. все приять м прократенной принисаль, что стари у меннучал спохванил в нени, которое привежил стотва объясненустий, и собранной город но метень. о настал после берчу посте него почествение так и с спозро были пришлы, которые серявине собыл порегают поиворании. все потом почего стути с порозал мнова и послыла\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"к, проживающий в доме 620 по ист-нэпп-ст\"\n",
            "к, проживающий в доме 620 по ист-нэпп-стропивался, но замок, стал было и постепала в конца, но субого жи по воду с сим, которые встетвить и кресткой стеренные слежила потом, тво в теть, что они уэтда неупречилась на более стано, когда я на принял слепа в кордами, тогда стольно белие, поступало на мое вобочие неубремие обрадным в этотой денерелило зладо к похопой, онаванивали наприняванной суминю, своих провов портовали и так того авлика\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"к, проживающий в доме 620 по ист-нэпп-ст\"\n",
            "к, проживающий в доме 620 по ист-нэпп-столькой бельер, туга, лужавае, большей слогие сействое, с конго-тоб селько мсем страшней, город сни, не времени я миску, а привер д моего предоставая тывались, то всем приятных пре зумать менени. и всем было и присне этуже золотавать весемые и повразние при, педера по дой почну часто больше ститьие зреды, необщем призстало прител собой спетичной времеска; останул своих предостаясть месть посли мне \n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"к, проживающий в доме 620 по ист-нэпп-ст\"\n",
            "к, проживающий в доме 620 по ист-нэпп-строкивал юго могда.\n",
            "а бринных покарутьст гроб этоторези скания, а за стутавлишесть меня смолльному ацери.\n",
            "это была поняванный с болом на принетечее я продной стения. и уэйди, есе на обазавал, и какущас с соно-непраздля в рохокой.\n",
            "и как так говорили пресзравние серяку. я вижел спузагомо жерь в не и сорую отти и слопить ум поскошение, что мутов попостело все помоту чупос ка спушан, горосли бешещи был\n",
            "Epoch 2/60\n",
            "   37/34212 [..............................] - ETA: 3:26:27 - loss: 0.5597 - acc: 0.8167"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}